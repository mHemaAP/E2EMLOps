# @package _global_

defaults:
  - override /data: dsports
  - override /model: msports
  - override /callbacks: default
  - override /logger: default
  - override /trainer: default

  # - override hydra/sweeper: optuna
  # - override hydra/launcher: joblib
  
seed: 42

data:
  batch_size: 8
  num_workers: 2
  pin_memory: False

trainer:
  min_epochs: 1
  max_epochs: 2
  limit_train_batches: 0.05
  limit_test_batches:  0.05
  limit_val_batches: 0.05

callbacks:
  model_checkpoint:
    dirpath: ${paths.output_dir}/checkpoints
    monitor: "val/acc"
    filename: "epoch_{epoch:03d}"
    mode: "max"
    save_top_k: 1
    save_last: true


task_name: "hparams"  #used in hydra-config to write logs
script: false

tags:
  - sports
  - "hparams"


# set False to skip model training
train: True

# evaluate on test set, using best model weights achieved during training
# lightning chooses best weights based on the metric specified in checkpoint callback
test: True


hydra:
  mode: MULTIRUN
  sweeper:
    sampler:
      _target_: optuna.samplers.TPESampler
      seed: 32
      n_startup_trials: 2
    direction: "minimize"   # test/loss_epoch  on return in train.py
    study_name: optimal_searching
    n_trials: 1
    n_jobs: 1
    params:
    # https://github.com/facebookresearch/hydra/discussions/2906
      ++model.stem_type: choice('patch','overlap')
      ++model.act_layer: choice('relu','gelu')
      ++model.global_pool: choice('avg','fast')
      ++model.depths: "[2,2,6,2],[3,3,9,3]"
      ++model.dims: "[24,48,22,168],[12,32,44,96]"
      ++model.kernel_sizes: "[3, 5, 7, 9],[3,3,3,3]"
      ++model.use_pos_emb: "[False,True,False,False], [True,True,True,False]"

  launcher:
    n_jobs: 1
    verbose: 1
    pre_dispatch: 2*n_jobs


logger:
  tensorboard:
    name: dim_${model.dims}-stem_${model.stem_type}-act_${model.act_layer}-pool_${model.global_pool}-dep_${model.depths}-kernel_${model.kernel_sizes}-posemb_${model.use_pos_emb}"